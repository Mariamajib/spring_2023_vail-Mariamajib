# Classification Loss Functions

## Topics covered in today's module
* Kullback Leibler Divergence Loss
* Binary Cross-Entropy
* Categorical Cross-Entropy
* Sparse Categorical Cross-Entropy

## Main takeaways from doing today's assignment
* Classification Loss Function represent the price paid of predictions in problems of indentifying which category a particular observation belongs to.

* Examples of classification loss function
  * Log loss
  * Focal loss
  * Exponential loss
  * Hinge loss
  * Relative entropy loss
  
* Kullback Leibler Divergence Loss is a measure of how a distribution varies from a reference distribution or a baseline distribution. 

* A Kullback Leibler Divergence Loss of zero means that both the probability distributions are identical.

                                            ğ¾ğ·ğ¿(ğ‘||ğ‘)=âˆ«ğ‘¥ğ‘(ğ‘¥)logğ‘(ğ‘¥)ğ‘(ğ‘¥)ğ‘‘ğ‘¥ 

* Cross-entropy is a measured by calculating the difference between two probability distributions.

* Kullback Leibler Divergence calculates the relative entropy between two probability distributions, whereas cross-entropy calculate the total entropy between the distributions.

* Binary Cross Entropy is a loss function that is used in binary classification tasks which are only two choices (yes or no, A or B, 0 or 1, left or right).

                                           ğµğ¶ğ¸=âˆ’1ğ‘âˆ‘ğ‘–=1ğ‘ğ‘¦ğ‘–â‹…log(ğ‘(ğ‘¦ğ‘–))+(1âˆ’ğ‘¦ğ‘–)â‹…log(1âˆ’ğ‘(ğ‘¦ğ‘–)) 
                                           
* Multi-class classification problem deal with mutually exclusive classes which needs categorical cross entropy loss function.  

* Multi-label classification deal with non-exclusive classes where an input may belong to more than one class and this needs binary cross entropy.

* Categorical cross entropy can be used in all kind of classification problem while Sparse categorical cross entropy can be used wnen each input belongs to single class only having all 0's except just a single element 1 (one-hot-encoding).
 


## Challenging, interesting, or exciting aspects of today's assignment
* It was interesting learning about the application of classification loss function  becuase we discussed classification loss function under types of loss functions in the previous assignment.

## Additional resources used 

